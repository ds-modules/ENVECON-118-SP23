{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Bootcamp Part 5\n",
    "\n",
    "## stargazer, xtable, robust standard errors, and fixed effects regressions\n",
    "\n",
    "\n",
    "This bootcamp will help us get more comfortableusing **stargazer** and **xtable** to produce high-quality results and summary statistics tables, and using `felm()` from the **lfe** package for regressions (both fixed effects and regular OLS).\n",
    "\n",
    "\n",
    "For today, let's load a few packages and read in a dataset on residential water use for residents in Alameda and Contra Costa Counties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "Here we'll load in our necessary packages and the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(haven)\n",
    "library(lfe)\n",
    "library(stargazer)\n",
    "library(xtable)\n",
    "\n",
    "# load in wateruse data, add in measure of gallons per day \"gpd\"\n",
    "waterdata <- read_dta(\"wateruse.dta\") %>%\n",
    "    mutate(gpd = (unit*748)/num_days)\n",
    "head(waterdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics Tables with xtable\n",
    "\n",
    "`xtable` is a useful package for producing custom summary statistics tables. let's say we're interested in summarizing water use ($gpd$) and degree days ($degree\\_days$) according to whether a lot is less than or greater than one acre ($lotsize_1$) or more than 4 acres ($lotsize_4$):\n",
    "\n",
    "`homesize <- waterdata %>%\n",
    "    select(hh, billingcycle, gpd, degree_days, lotsize) %>%\n",
    "    drop_na() %>%\n",
    "    mutate(lotsize_1 = ifelse((lotsize < 1), \"< 1\", \">= 1\"),\n",
    "           lotsize_4 = ifelse((lotsize > 4), \"> 4\", \"<= 4\"))\n",
    "head(homesize)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to create summary statistics for these two variables for both levels of $lotsize\\_1$ and $lotsize\\_4$ using `summarise()`:\n",
    "\n",
    "`sumstat_1 <- homesize %>%\n",
    "    group_by(lotsize_1) %>%\n",
    "    summarise(mean_gpd = mean(gpd), \n",
    "              mean_degdays = mean(degree_days))\n",
    "sumstat_1`\n",
    "\n",
    "`sumstat_4 <- homesize %>%\n",
    "    group_by(lotsize_4) %>%\n",
    "    summarise(mean_gpd = mean(gpd), \n",
    "              mean_degdays = mean(degree_days))\n",
    "sumstat_4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can use `xtable()` to put them into the same table!\n",
    "\n",
    "`full <- xtable(cbind(t(sumstat_1), t(sumstat_4)))\n",
    "rownames(full)[1] <- \"Lotsize Group\"\n",
    "colnames(full) <- c(\"lotsize_1 = 1\", \"lotsize_1 = 0\", \"lotsize_4 = 0\", \"lotsize_4 =1\")\n",
    "full`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a table `full` that is an xtable object. \n",
    "\n",
    "We can also spit this table out in html or latex form if needed using the `print.xtable()` function on our xtable `full`, specifying `type = \"html\":\n",
    "\n",
    "`print.xtable(full, type = \"html\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the html code here to see how it appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tables in Stargazer\n",
    "\n",
    "`stargazer` is a super useful package for producing professional-quality regression tables. While it defaults to producing LaTeX format tables (a typesetting language a lot of economists use), for use in our class we can also produce html code that can easily be copied into text cells and formatted perfectly.\n",
    "\n",
    "If we run the following three regressions: \n",
    "\n",
    "\\begin{align*} GPD_{it} &= \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it} ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(1)\\\\\n",
    " GPD_{it} &= \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it} + \\beta_3 lotsize_{i}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(2)\\\\\n",
    "GPD_{it} &= \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it} + \\beta_3 lotsize_{i} + \\beta_4 Homeval_i~~~~~~~~~~~~~~~~~~(3)\n",
    "\\end{align*}\n",
    "\n",
    "We might want to present the results side by side in the same table so that we can easily compare coefficients from one column to the other. To do that with `stargazer`, we can \n",
    "\n",
    "1. Run each regression, storing them in memory\n",
    "2. Run `stargazer(reg1, reg2, reg3, ..., type )` where the first arguments are all the regression objects we want in the table, and telling R what type of output we want\n",
    "\n",
    "If we specify `type = \"text\"`, we'll get the table displayed directly in the output window:\n",
    "\n",
    "`reg_a <- lm(gpd ~ degree_days + precip, waterdata)\n",
    "reg_b <- lm(gpd ~ degree_days + precip + lotsize, waterdata)\n",
    "reg_c <- lm(gpd ~ degree_days + precip + lotsize + homeval, waterdata)`\n",
    "\n",
    "`stargazer(reg_a, reg_b, reg_c, type = \"text\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we specify `type = \"html\"`, we'll get html code that we need to copy and paste into a text/markdown cell:\n",
    "\n",
    "`stargazer(reg_a, reg_b, reg_c, type = \"html\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do is copy and paste that html code from the output into a text cell and we've got our table!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(copy your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get a nice looking regression table with all three models side by side! This makes it easy to see how the coefficient on lot size falls when we add in home value, letting us quickly figure out the sign of correlation between the two.\n",
    "\n",
    "## Table Options\n",
    "\n",
    "Stargazer has a ton of different options for customizing the look of our table with optional arguments, including\n",
    "* `title` lets us add a custom title\n",
    "* `column.labels` lets you add text labels to the columns\n",
    "* `covariate.labels` lets us specify custom labels for all our variables other than the variable names. Specify each label in quotations in the form of a vector with `c()`\n",
    "* `ci = TRUE` adds in confidence intervals (by default for the 10\\% level, but you can change it to the 1\\% level with `ci.level = 0.99`\n",
    "* `intercept.bottom = FALSE` will move the constant to the top of the table\n",
    "* `digits` lets you choose the number of decimal places to display\n",
    "* `notes` lets you add some notes at the bottom\n",
    "\n",
    "For example, we could customize the above table as\n",
    "\n",
    "`stargazer(reg_a, reg_b, reg_c, type = \"text\",\n",
    "         title = \"Water Use, Weather, and Home Characteristics\",\n",
    "         column.labels = c(\"Weather\", \"With Lotsize\", \"With HomeVal\"),\n",
    "          covariate.labels = c(\"Intercept\", \"Degree Days\", \"Precipitation (mm)\", \"Lot Size (Acres)\", \"Home Value (USD)\"),\n",
    "          intercept.bottom = FALSE,\n",
    "          digits = 2,\n",
    "          note = \"Isn't stargazer neat?\"\n",
    "          )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics Tables in Stargazer\n",
    "\n",
    "Can we use Stargazer for summary statistics tables too? You bet we can! \n",
    "\n",
    "Stargazer especially comes in handy if we have a lot of variables we want to summarize and one or no variables we want to group them on. This approach works especially well with `across()` within `summarise()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say we wanted to summarise the median and variance of `gpd`, `precip`, and `degree_days` by whether the home was built after 1980 or not. Rather than create separate tables for all of the variables and merge them together like with xtable, we can just summarise across with\n",
    "\n",
    "`ss_acr <- mutate(waterdata, pre_80 = ifelse(yearbuilt < 1980, \"1. Pre-1980\", \"2. 1980+\")) %>%\n",
    "    group_by(pre_80) %>%\n",
    "    summarise(across(.cols = c(gpd, precip, degree_days),\n",
    "                     .fns = list(Median = median, Variance = var)))\n",
    "ss_acr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `ifelse()` is a function that follows the format\n",
    "\n",
    "`ifelse(Condition, Value if True, Value if False)`\n",
    "\n",
    "Here our condition is that the $yearbuilt$ variable is less than 1980. If it’s true, we want this\n",
    "new variable to take on the label \"1. Pre-1980\", and otherwise\n",
    "be \"2. 1980+\".\n",
    "\n",
    "This table then contains everything we want, but having it displayed \"wide\" like this is a bit tough to see. If we wanted to display it \"long\" where there is one column for each or pre-1980 and post-1980 homes, we can just use the transpose function `t()`. Placing that within the `stargazer()` call and specifying that we want html code then gets us\n",
    "\n",
    "`stargazer(t(ss_acr), type = \"html\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(copy your html code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heteroskedasticity-Robust Standard Errors \n",
    "\n",
    "\n",
    "There are often times where you want to use heteroskedasticity-robust standard errors in place of the normal kind to account for situations where we might be worried about violating our homoskedasticity assumption. To add robust standard errors to our table, we'll take advantage of the `lmtest` and `sandwich` packages. (We have not yet loaded these packages in the preamble. So, if you run below code as is, you obtain an error message that reads \"could not find function \"coeftest,\" SO, add the above two packages to your preablem.)\n",
    "\n",
    "If we want to see the coefficient table from Regression B with robust standard errors, we can use the `coeftest()` function as specified below:\n",
    "\n",
    "`coeftest(reg_b, vcov = vcovHC(reg_b, type = \"HC1\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the `vcovHC(reg_a, type = \"HC1\")` part is doing is telling R we want to calculate standard errors using the heteroskedasticity-robust approach (i.e. telling it a specific form of the variance-covariance matrix between our residuals). `coeftest()` then prints the nice output table. \n",
    "\n",
    "While this is a nice way to view the robust standard errors in a summary-style table, sometimes we want to extract the robust standard errors so we can use them elsewhere - like in stargazer!\n",
    "\n",
    "To get a vector of robust standard errors from Regression B, we can use the following:\n",
    "\n",
    "`robust_b <- sqrt(diag(vcovHC(reg_b, type = \"HC1\")))`\n",
    "\n",
    "`robust_b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which matches the robust standard errors using `coeftest()` earlier. But woah there, that's a function nested in a function nested in *another function*! Let's break this down step-by-step:\n",
    "\n",
    "`vcov_b <- vcovHC(reg_b, type = \"HC1\")`\n",
    "\n",
    "This first `vcov_b` object is getting the entire variance-covariance matrix for our regression coefficients. Since we again specified `type = \"HC1\"`, we ensure we get the heteroskedasticity-robust version of this matrix (if we had instead specified `type = \"constant\"` we would be assuming homoskedasticity and would get our usual variance estimates).\n",
    "\n",
    "What this looks like is\n",
    "\n",
    "\n",
    "$$VCOV_b = \\begin{matrix}{}\n",
    "\\widehat{Var}(\\hat \\beta_0)       & \\widehat{Cov}(\\hat \\beta_0, \\hat\\beta_1)  & \\widehat{Cov}(\\hat \\beta_0, \\hat\\beta_2)  \\\\\n",
    " \\widehat{Cov}(\\hat \\beta_1, \\hat\\beta_0) & \\widehat{Var}(\\hat \\beta_1)         & \\widehat{Cov}(\\hat \\beta_1, \\hat\\beta_2) \\\\\n",
    " \\widehat{Cov}(\\hat \\beta_2, \\hat\\beta_0)  & \\widehat{Cov}(\\hat \\beta_2, \\hat\\beta_1) & \\widehat{Var}(\\hat \\beta_2)  \n",
    "\\end{matrix}$$\n",
    "\n",
    "Where each element is $\\hat\\sigma_i$ in the ith row mutiplied by $\\hat\\sigma_j$ in the jth column. Note that when $i = j$ in the main diagonal, we get the variance estimate for $\\hat \\beta_i$!\n",
    "\n",
    "You can check this by running the following lines:\n",
    "\n",
    "`vcov_b <- vcovHC(reg_b, type = \"HC1\")\n",
    " vcov_b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`var_b <- diag(vcov_b)`\n",
    "\n",
    "The `diag()` function extracts this main diagonal, giving us a vector of our robust estimated variances\n",
    "\n",
    "`robust_b <- sqrt(var_b)`\n",
    "\n",
    "And taking the square root gets us our standard error estimates for our $\\hat\\beta$'s!\n",
    "\n",
    "See the process by running the following lines:\n",
    "\n",
    "`var_b <- diag(vcov_b)\n",
    " var_b`\n",
    "\n",
    "`robust_b <- sqrt(var_b)\n",
    " robust_b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stargazer and Heteroskedasticity-Robust Standard Errors \n",
    "\n",
    "Now that we know how to get our robust standard errors, we can grab them for all three of our regressions and add them to our beautiful stargazer table:\n",
    "\n",
    "`robust_a <- sqrt(diag(vcovHC(reg_a, type = \"HC1\")))\n",
    "robust_b <- sqrt(diag(vcovHC(reg_b, type = \"HC1\")))\n",
    "robust_c <- sqrt(diag(vcovHC(reg_c, type = \"HC1\")))`\n",
    "\n",
    "\n",
    "`stargazer(reg_a, reg_b, reg_c, \n",
    "           type = \"html\",\n",
    "          se = list(robust_a, robust_b, robust_c),\n",
    "          omit.stat = \"f\")`\n",
    "          \n",
    "Here we're adding the robust standard errors to `stargazer()` with the `se =` argument (combining them together in the right order as a list). I'm also omitting the overall F test at the bottom with `omit.stat = \"f\"` since we'd need to correct that too for heteroskedasticity. \n",
    "\n",
    "Try running this code below to see how the standard errors change when we use robust standard errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the table code here and run the cell to see it formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that looks pretty good, though note that the less than signs in the note for significance labels don't appear right. This is because html is reading the < symbol as a piece of code and not the math symbol. To get around this, you can add dollar signs around the < signs in the html code for the note to have the signs display properly:\n",
    "\n",
    "`<sup>*</sup>p $<$ 0.1; <sup>**</sup>p $<$ 0.05; <sup>***</sup>p $<$ 0.01</td>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fixed Effects Regression\n",
    "\n",
    "\n",
    "Today we will practice with fixed effects regressions in __R__. We have two different ways to estimate the model, and we will see how to do both and the situations in which we might favor one versus the other.\n",
    "\n",
    "Let's give this a try using the dataset `wateruse.dta`. The subset of households are high water users, people who used over 1,000 gallons per billing cycle. We have information on their water use, weather during the period, as well as information on the city and zipcode of where the home is located, and information on the size and value of the house.\n",
    "\n",
    "Suppose we are interested in running the following panel regression of residential water use:\n",
    "\n",
    "$$ GPD_{it} = \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it} ~~~~~~~~~~~~~~~~~~~~~~~(1)$$\n",
    "\n",
    "Where $GPD$ is the gallons used per day by household $i$ in billing cycle $t$, $degree\\_days$ the count of degree days experienced by the household in that billing cycle (degree days are a measure of cumulative time spent above a certain temperature threshold), and $precip$ the amount of precipitation in millimeters.\n",
    "\n",
    "`reg1 <- lm(gpd ~ degree_days + precip, data = waterdata)\n",
    "summary(reg1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we obtain an estimate of $\\hat\\beta_1 = 0.777$, telling us that an additional degree day per billing cycle is associated with an additional $0.7769$ gallon used per day. These billing cycles are roughly two months long, so this suggests an increase of roughly 47 gallons per billing cycle. Our estimate is statistically significant at all conventional levels, suggesting residential water use does respond to increased exposure to high heat.\n",
    "\n",
    "We estimate a statistically insignificant coefficient on additional precipitation, which tells us that on average household water use in our sample doesn't adjust to how much it rains.\n",
    "\n",
    "We might think that characteristics of the home impact how much water is used there, so we add in some home controls:\n",
    "\n",
    "\n",
    "$$ GPD_{it} = \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it}  + \\beta_3 lotsize_{i} + \\beta_4 homesize_i + \\beta_5 num\\_baths_i + \\beta_6 num\\_beds_i + \\beta_7 homeval_i~~~~~~~~~~~~~~~~~~~~~~~(2)$$\n",
    "\n",
    "`reg2 <- lm(gpd ~ degree_days + precip + lotsize + homesize + num_baths + num_beds + homeval, data = waterdata)\n",
    "summary(reg2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our coefficient on $degree\\_days$ remains statistically significant and doesn't change much, so we find that $\\hat\\beta_1$ is robust to the addition of home characteristics. Of these characteristics, we obtain statistically significant coefficients on the size of the lot in acres ($lotsize$), the size of the home in square feet ($homesize$), and the number of bedrooms in the home ($num_beds$).\n",
    "\n",
    "We get a curious result for $\\hat\\beta_6$: for each additional bedroom in the home we predict that water use will *fall* by 48 gallons per day. \n",
    "\n",
    "### Discussion: what might be driving this effect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are likely a number of sources of omitted variable bias in the previous model, we think it might be worth including some fixed effects in our model. These will allow us to control for some of the unobserved sources of OVB without having to measure them directly!\n",
    "\n",
    "## Method 1: Fixed Effects with lm() \n",
    "\n",
    "Up to this point we have been running our regressions using the `lm()` function. We can still use `lm()` for our fixed effects models, but it takes some more work and gets increasingly time-intensive as datasets get large.\n",
    "\n",
    "Recall that we can write our general panel fixed effects model as \n",
    "\n",
    "$$ y_{it} = \\beta x_{it} + \\mathbf{a}_i + \\mathbf{d}_t + u_{it} $$\n",
    "\n",
    "* $y$ our outcome of interest, which varies in both the time and cross-sectional dimensions\n",
    "* $x_{it}$ our set of time-varying unit characteristics\n",
    "* $\\mathbf{a}_i$ our set of unit fixed effects\n",
    "* $\\mathbf{d}_t$ our time fixed effects\n",
    "\n",
    "We can estimate this model in `lm()` provided we have variables in our dataframe that correspond to each level of $a_i$ and $d_t$. This means we'll have to generate them before we can run any regression.\n",
    "\n",
    "### Generating Dummy Variables\n",
    "\n",
    "In order to include fixed effects for our regression, we can first generate the set of dummy variables that we want. For example, if we want to include a set of city fixed effects in our model, we need to generate them.\n",
    "\n",
    "We can do this in a few ways.\n",
    "\n",
    "1. First, we can use `mutate()` and add a separate column for each individual city:\n",
    "\n",
    "`fe_1 <- waterdata %>%\n",
    "    mutate(city_1 = as.numeric((city==1)),\n",
    "           city_2 = as.numeric((city ==2)),\n",
    "           city_3 = as.numeric((city ==3))) %>%\n",
    "    select(hh, city, city_1, city_2, city_3)\n",
    "head(fe_1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be super tedious though when we have a bunch of different levels of our variable that we want to make fixed effects for. In this case, we have 27 different cities.\n",
    "\n",
    "2. Alternatively, we can use the `spread()` function to help us out. Here we add in a constant variable `v` that is equal to one in all rows, and a copy of city that adds \"city_\" to the front of the city number. Then we pass the data to `spread`, telling it to split the variable `cty` into dummy variables for all its levels, with all the \"false\" cases filled with zeros.\n",
    "\n",
    "`fe_2 <- waterdata %>%\n",
    "select(hh, city, billingycle)`\n",
    "\n",
    "\n",
    "`fe_2 %>%\n",
    "   mutate(v = 1, cty = paste0(\"city_\", city)) %>% \n",
    "   spread(cty, v, fill = 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is much easier! \n",
    "\n",
    "This is a useful approach if you want to produce summary statistics for the fixed effects (i.e. what share of the sample lives in each city), but isn't truly necessary.\n",
    "\n",
    "Alternatively, we can tell R to read our fixed effects variables as factors:\n",
    "\n",
    "`lm(gpd ~ degree_days + precip + factor(city), data = waterdata)`\n",
    "\n",
    "`factor()` around $city$ tells R to split city into dummy variables for each unique value it takes. R will then drop the first level when we run the regression - in our case making the first city our omitted group.\n",
    "\n",
    "\n",
    "`reg3 <- lm(gpd ~ degree_days + precip + factor(city), data = waterdata)\n",
    "summary(reg3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to run the regression\n",
    "\n",
    "\n",
    "$$ GPD_{it} = \\beta_0 + \\beta_1 degree\\_days_{it} + \\beta_2 precip_{it}  + \\mathbf{a}_i + \\mathbf{d}_t~~~~~~~~~~~~~~~~~~~~~~~(2)$$\n",
    "\n",
    "Where $\\mathbf{a}_i$ are our city fixed effects, and $\\mathbf{d}_t$ our billing cycle fixed effects:\n",
    "\n",
    "`fe_reg1 <- lm(gpd ~ degree_days + precip + factor(city) + factor(billingcycle), data = waterdata)\n",
    "summary(fe_reg1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__R__ automatically chose the first dummy variable for each set of fixed effect (city 1 and billing cycle 1) to leave out as our omitted group. \n",
    "\n",
    "Now that we account for which billing cycle we're in (i.e. whether we're in the winter or whether we're in the summer), we find that the coefficient on $degree\\_days$ is now much smaller and statistically insignificant. This makes sense, as we were falsely attributing the extra water use that comes from seasonality to temperature on its own. Now that we control for the season we're in via billing cycle fixed effects, we find that deviations in temperature exposure during a billing cycle don't result in dramatically higher water use within the sample.\n",
    "\n",
    "### Discussion: Why did we drop the home characteristics from our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Fixed Effects with felm()\n",
    "\n",
    "Alternatively, we could do everything way faster using the `felm()` function from the package __lfe__. This package doesn't require us to produce all the dummy variables by hand. Further, it performs the background math way faster so will be much quicker to estimate models using large datasets and many variables.\n",
    "\n",
    "The syntax we use is now \n",
    "\n",
    "`felm(y ~ x1 + x2 + ... + xk | FE_1 + FE_2 + ..., data = df)`\n",
    "\n",
    "* The first section $y \\sim x1 + x2 +... xk$ is our formula, written the same way as with `lm()` - but omitting the fixed effects\n",
    "* We now add a `|` and in the second section we specify our fixed effects. Here we say $FE\\_1 + FE\\_2$ which tells __R__ to include fixed effects for each level of the variables $FE\\_1$ and $FE\\_2$.\n",
    "* we add the data source after the comma, as before.\n",
    "\n",
    "Let's go ahead and try this now with our water data model:\n",
    "\n",
    "`fe_reg2 <- felm(gpd ~ degree_days + precip | city + billingcycle, data = waterdata)\n",
    "summary(fe_reg2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we estimate the exact same coefficients on $degree\\_days$ and $precip$ as in the case where we specified everything by hand! We didn't have to mutate our data or add any variables. The one potential downside is that this approach doesn't report the fixed effects themselves by default. The tradeoff is that `felm` runs a lot faster than `lm`, especially with large datasets. \n",
    "\n",
    "We can also recover the fixed effects with getfe(): \n",
    "\n",
    "`getfe(fe_reg2, se = TRUE, robust = TRUE)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the argument `se = TRUE` tells it to produce standard errors too, and `robust = TRUE` further indicates that we want heteroskedasticity-robust standard errors.\n",
    "\n",
    "\n",
    "Note that this approach doesn't give you the same reference groups as before, but we get the same relative values. Note that before the coefficient on $city2$ was 301.7 and now is 73.9. But the coefficient on $city1$ is -227.8, and if we subtract $city1$ from $city2$ to get the difference in averages for city 2 relative to city 1 we get $73.9 - (-227.8) = 301.7$, the same as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Effects Practice Question #1\n",
    "\n",
    "#### From a random sample of agricultural yields Y (1000 dollars per acre) for region $i$ in year $t$ for the US, we have estimated the following eqation:\n",
    "\n",
    " \\begin{align*} \\widehat{\\log(Y)}_{it} &=\t0.49\t+ .01 GE_{it} ~~~~ \tR^2 = .32\\\\\n",
    "\t&~~~~~(.11)\t ~~~~ (.01)                ~~~~  n = 1526       \\end{align*}\n",
    "\n",
    "#### (a) Interpret the results on the Genetically engineered ($GE$) technology on yields. (follow SSS= Sign Size Significance)\n",
    "\n",
    "#### (b) Suppose $GE$ is used more on the West Coast, where crop yields are also higher. How would the estimated effect of GE change if we include a West Coast region dummy variable in the equation? Justify your answer.\n",
    "\n",
    "#### (c) If we include region fixed effects, would they control for the factors in (b)? Justify your answer.\n",
    "\n",
    "#### (d)  If yields have been generally improving over time and GE adoption was only recently introduced in the USA, what would happen to the coefficient of GE if we included year fixed effects?\n",
    "\n",
    "\n",
    "\n",
    "# Fixed Effects Practice Question #2\n",
    "\n",
    "#### A recent paper investigates whether advertisement for Viagra causes increases in birth rates in the USA.  Apparently, advertising for products, including Viagra, happens on TV and reaches households that have a TV within a Marketing region and does not happen in areas outside a designated marketing region. What the authors do is look at hospital birth rates in regions inside and near the advertising region border  and collect data on dollars per 100 people (Ads) for a certain time, and compare those to the birth rates in hospitals located outside and near the advertising region designated border. They conduct a panel data analysis and estimate the following model:\n",
    "\n",
    "$$ Births_{it} = \\beta_0 + \\beta_1 Ads + \\beta_2 Ads^2 + Z_i + M_t + u_{it}$$\n",
    "\n",
    "#### Where $Z_i$ are zipcode fixed effects and $M_t$ monthly fixed effects.\n",
    "\n",
    "#### (a) Why do the authors include Zip Code Fixed Effects? In particular, what would be a variable that they are controlling for when adding Zip Code fixed effects that could cause a problem when interpreting the marginal effect of ad spending on birth rates? What would that (solved) problem be?\n",
    "\n",
    "#### (b) Why do they add month fixed effects? \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
